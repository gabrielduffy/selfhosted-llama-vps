# Self-Hosted LLM (Llama-3.1) para Easypanel

Este repositÃ³rio contÃ©m a configuraÃ§Ã£o para rodar uma LLM completa (Interface + API) em uma VPS usando Easypanel.

## ðŸš€ Como instalar no Easypanel

1. Crie um novo **App** no Easypanel.
2. Na aba **Source**, conecte este repositÃ³rio GitHub.
3. Na aba **Domains**, configure o seu domÃ­nio ou use um subdomÃ­nio para acessar a interface.
4. Na aba **Storage**, crie um volume persistente:
   - **Mount Path:** `/app/backend/data`
5. Na aba **Environment**, vocÃª pode adicionar:
   - `WEBUI_SECRET_KEY`: (uma string aleatÃ³ria para seguranÃ§a)

## ðŸ–¥ï¸ Acesso
- **Interface:** `http://seu-dominio:8080`
- **API (estilo OpenAI):** `http://seu-dominio:11434/v1`

## ðŸ§  Modelos
Por padrÃ£o, este o container tentarÃ¡ baixar o `llama3.1:8b`. VocÃª pode baixar outros (ex: `glm4`) diretamente pela interface do Open WebUI em:
*Settings -> Models -> Pull a model from Ollama.com*
